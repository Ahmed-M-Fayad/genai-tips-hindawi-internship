{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lecture 1 Practice","metadata":{}},{"cell_type":"markdown","source":"Retrieve Models from HuggingFace and Trying them","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Installing Required Packages","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.52.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:30:24.029330Z","iopub.execute_input":"2025-10-21T00:30:24.029526Z","iopub.status.idle":"2025-10-21T00:30:38.392763Z","shell.execute_reply.started":"2025-10-21T00:30:24.029500Z","shell.execute_reply":"2025-10-21T00:30:38.392029Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.52.4\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers==4.52.4)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.52.4) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.35.3 transformers-4.52.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## HuggingFace Login","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:30:38.394515Z","iopub.execute_input":"2025-10-21T00:30:38.394754Z","iopub.status.idle":"2025-10-21T00:30:38.657862Z","shell.execute_reply.started":"2025-10-21T00:30:38.394734Z","shell.execute_reply":"2025-10-21T00:30:38.657096Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:42.521981Z","iopub.execute_input":"2025-10-21T00:31:42.522344Z","iopub.status.idle":"2025-10-21T00:31:42.536635Z","shell.execute_reply.started":"2025-10-21T00:31:42.522322Z","shell.execute_reply":"2025-10-21T00:31:42.535722Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37af169ef7a24372bb4784157e4d6c8e"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Model 1: GPT-2 (Text Generator)","metadata":{}},{"cell_type":"code","source":"from transformers import set_seed, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:54.582741Z","iopub.execute_input":"2025-10-21T00:31:54.583406Z","iopub.status.idle":"2025-10-21T00:31:54.587020Z","shell.execute_reply.started":"2025-10-21T00:31:54.583380Z","shell.execute_reply":"2025-10-21T00:31:54.586129Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# setting randomization\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:54.998980Z","iopub.execute_input":"2025-10-21T00:31:54.999472Z","iopub.status.idle":"2025-10-21T00:31:55.003715Z","shell.execute_reply.started":"2025-10-21T00:31:54.999443Z","shell.execute_reply":"2025-10-21T00:31:55.003132Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# getting model\ngenerator = pipeline(\"text-generation\", model='gpt2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:55.233600Z","iopub.execute_input":"2025-10-21T00:31:55.234011Z","iopub.status.idle":"2025-10-21T00:31:55.962602Z","shell.execute_reply.started":"2025-10-21T00:31:55.233993Z","shell.execute_reply":"2025-10-21T00:31:55.961730Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"response = generator(\n    \"Hello, my name is john and i am an AI engineer\",\n    max_length=60, num_return_sequences=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:55.964132Z","iopub.execute_input":"2025-10-21T00:31:55.964673Z","iopub.status.idle":"2025-10-21T00:31:58.780781Z","shell.execute_reply.started":"2025-10-21T00:31:55.964654Z","shell.execute_reply":"2025-10-21T00:31:58.780201Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"for res in response:\n    print(res.get('generated_text'))\n    print('-'*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:31:58.781525Z","iopub.execute_input":"2025-10-21T00:31:58.781737Z","iopub.status.idle":"2025-10-21T00:31:58.786266Z","shell.execute_reply.started":"2025-10-21T00:31:58.781722Z","shell.execute_reply":"2025-10-21T00:31:58.785519Z"}},"outputs":[{"name":"stdout","text":"Hello, my name is john and i am an AI engineer for the internet. I have some big projects in mind when i will be working on creating a 3D printer for my products. This was my goal and i am so happy with this little app. And thanks to all those who support it, you get to take your projects to the next level and get your hands on a 3D printer that will allow you to build things that are truly amazing and look like things you could never imagine.\n\nIf you like what you see on this app, sign up for my newsletter and follow me on twitter.\n------------------------------\nHello, my name is john and i am an AI engineer. I'm from the United States of America.My first hobby was playing with computers. I was working for a company called KISS.I came across KISS on my way to work and they were kind enough to give me an AI for a short time. I came back to KISS in August of 2012 and I had a really good experience.I came back to KISS in December of 2012 and it was a great experience. I did some research into AI, I got a great deal from KISS as well as a bunch of other companies.I thought it was a great idea in that all the guys at KISS would not be able to figure out how to get their hands on a robot. I was so excited that I finally got a chance to put the AI program in a real robot. I was on a plane to work in France when I got there. It was just a great experience. I was very excited to start working with an AI, it was such a cool experience.I was really excited about going to a meeting at KISS, I was really excited about working with this guy. It was an amazing experience. I was very impressed with all the AI.I have to say I was very happy with the experience, it was really fun\n------------------------------\nHello, my name is john and i am an AI engineer who has been a part of the Linux community since 1989. I am the founder of a new company called AI Engineering. I am looking to develop AI for the future and help to drive the adoption of AI in the software industry. I will be speaking at the AI Engineering conference in Toronto. You can find a full list of my speakers and details about me there.\n\nWe are currently on a project to create a new kind of AI that can use a deep learning algorithm to solve complex data sets. We have done the research and are now on a project to create a new type of AI that can work with large quantities of data and is able to process it quickly. To learn more about this project, follow the links at the end of this article.\n\nI will be talking about our project on the following topics:\n\nWe will be using OpenCL to run our AI engine.\n\nWe will be using a deep learning approach to solve a very simple problem\n\nWe will be using advanced Deep Learning algorithms for better performance and AI.\n\nWe will be using a new type of AI called Deep Learning, or Deep Learning in Action.\n\nWe will be using Deep Learning in Action in a very fast and efficient way.\n\nWe are going\n------------------------------\nHello, my name is john and i am an AI engineer at IBM. I am looking for some help for my project. I have been looking for a good job for a long time now. I recently joined a company called EAPL (Advanced Placement Leadership and Training). I have been doing this for a long time now. I have been really impressed with some of the things i can learn from this training. I would like to apply to IBM, but so far I have not been accepted. I would like to apply to the SRI as well. Thank you so much for reading and I hope this helps you.\n\nI am looking for a full-time job, I am currently working as a technical assistant at IBM. I am also looking for a new computer engineer. I am looking to get a job as a software engineer and have a lot of experience working in software development. Since I am a software engineer, I would like to be able to help my clients with their IT issues. I am looking for a salary of $80,000. I am looking for a full-time job as a software engineer. I have been working with a team of engineers for over a month and have been working very well for them. I would like to work in a very advanced computer science program. I would like to\n------------------------------\nHello, my name is john and i am an AI engineer at a research lab in the UK and i have been working on this for years. i am very impressed with this project and i am very excited to share this with you.\n\nThis is not a new project, it has been in the works for years.\n\nI have been working on the project for almost a year but i am not ready to publish until i am sure that the funding is secure.\n\nYou can read more about my progress in my blog here.\n\nI've created a project that can be used to explore the possibilities of AI and robotics. I've created a prototype of an AI system that can be used to help scientists answer questions about the human race, in order to develop new forms of AI.\n\nThis is my first AI system, I am currently in the process of building an AI system which will be used by future researchers to help them study the human race.\n\nI'm currently developing the first prototype of a robotic robot called the TARDIS (which we have already built). I'm working with several other companies on a prototype of this system which will soon be made available to the public.\n\nI am now able to demonstrate the TARDIS system in action. It is a small robot with a small humanoid body\n------------------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Model 2: Bart (English Summarizer)","metadata":{}},{"cell_type":"code","source":"# getting model\nsummarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:17.426541Z","iopub.execute_input":"2025-10-21T00:32:17.427218Z","iopub.status.idle":"2025-10-21T00:32:19.029278Z","shell.execute_reply.started":"2025-10-21T00:32:17.427194Z","shell.execute_reply":"2025-10-21T00:32:19.028436Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"ARTICLE = \"\"\"\n## What Is Data Engineering?\n\n**Definition:** Development, implementation, and maintenance of systems that take raw data and produce high-quality, consistent information for downstream use (analysis, ML).\n\n**Data Engineering Lifecycle Stages:**\n1. Generation (source systems)\n2. Storage\n3. Ingestion\n4. Transformation\n5. Serving\n\n## Evolution of Data Engineering\n\n- **1980s-2000s:** Data warehousing era (BI, ETL)\n- **Early 2000s:** Big data emergence (Hadoop, MapReduce, cloud)\n- **2010s:** Big data engineering (Spark, streaming)\n- **2020s:** Data lifecycle engineering (abstraction, modularization, managed tools)\n\n## Data Engineering Lifecycle Details\n\n**Generation:** Understanding source systems producing data\n\n**Storage:** Choosing solutions for data at different \"temperatures\" (hot/lukewarm/cold based on access frequency)\n\n**Ingestion:**\n- Batch vs streaming\n- Push vs pull models\n- Key bottleneck in lifecycle\n\n**Transformation:** Converting data into useful forms (applying business logic, data modeling, featurization for ML)\n\n**Serving:**\n- Analytics (BI, operational, embedded)\n- Machine learning\n- Reverse ETL (feeding processed data back to source systems)\n\n## Six Undercurrents (Critical Foundations)\n\n**1. Security:** Principle of least privilege, encryption, access controls\n\n**2. Data Management:**\n- Data governance (discoverability, accountability, quality)\n- Metadata management (business, technical, operational, reference)\n- Master data management (golden records)\n- Data lineage (audit trail)\n\n**3. DataOps:**\n- Automation (CI/CD, version control)\n- Observability & monitoring (catching issues early)\n- Incident response (rapid problem resolution)\n\n**4. Data Architecture:** Designing current and future data systems\n\n**5. Orchestration:** Coordinating jobs via DAGs (Directed Acyclic Graphs), not just scheduling\n\n**6. Software Engineering:** Core coding, testing, streaming, infrastructure as code\n\n## Key Principles\n\n- Data maturity has 3 stages: Starting, Scaling, Leading\n- Type A engineers (abstraction) vs Type B (build custom)\n- Data engineers sit upstream from data scientists\n- Focus on ROI, cost reduction, minimizing risk, maximizing value\n- Avoid \"vanity projects\" - data must be consumed to have value\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:19.030502Z","iopub.execute_input":"2025-10-21T00:32:19.030834Z","iopub.status.idle":"2025-10-21T00:32:19.035220Z","shell.execute_reply.started":"2025-10-21T00:32:19.030815Z","shell.execute_reply":"2025-10-21T00:32:19.034603Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"summary = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:19.036096Z","iopub.execute_input":"2025-10-21T00:32:19.036470Z","iopub.status.idle":"2025-10-21T00:32:20.115367Z","shell.execute_reply.started":"2025-10-21T00:32:19.036447Z","shell.execute_reply":"2025-10-21T00:32:20.114575Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(summary[0].get('summary_text'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:20.116904Z","iopub.execute_input":"2025-10-21T00:32:20.117131Z","iopub.status.idle":"2025-10-21T00:32:20.121120Z","shell.execute_reply.started":"2025-10-21T00:32:20.117115Z","shell.execute_reply":"2025-10-21T00:32:20.120423Z"}},"outputs":[{"name":"stdout","text":"Data Engineering is the development, implementation, and maintenance of systems that take raw data and produce high-quality, consistent information for downstream use (analysis, ML) Data maturity has 3 stages: Starting, Scaling, Leading.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Model 3: Mistral (LLM)","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:20.121826Z","iopub.execute_input":"2025-10-21T00:32:20.122138Z","iopub.status.idle":"2025-10-21T00:32:20.132616Z","shell.execute_reply.started":"2025-10-21T00:32:20.122120Z","shell.execute_reply":"2025-10-21T00:32:20.132004Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:32:20.183761Z","iopub.execute_input":"2025-10-21T00:32:20.184272Z","iopub.status.idle":"2025-10-21T00:36:59.077378Z","shell.execute_reply.started":"2025-10-21T00:32:20.184251Z","shell.execute_reply":"2025-10-21T00:36:59.076793Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7adbe1ec6ab64b75a954319d9faa22eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41ea807747f4b56a0edf77e032888dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3233513529e24afcbdd2851a2bee0c2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"637d53cdab6349369742c73c875ecd47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3afd0cbf83a740228a0a32a2f14d6ec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea5e1f3946fa471487cc453b45be1f28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4484716c5d904c4b8e60baa28e4fa076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a812fd7ffb45f987bdfa6245b2ae88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4369ceaac5be41beb8ba5da893be6ecf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dae6638ad354b46a1c43466afc70e21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5d448678e4744aaabacf9a3983b5557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ecf29501214a42b555d15eee818f0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc303a06f5e4bb4a00e4ec4bc8cbb31"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Wrapping a function for Viz Output\ndef generate_text(prompt, max_length=100, num_return_sequences=1):\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:36:59.078452Z","iopub.execute_input":"2025-10-21T00:36:59.078713Z","iopub.status.idle":"2025-10-21T00:36:59.084721Z","shell.execute_reply.started":"2025-10-21T00:36:59.078695Z","shell.execute_reply":"2025-10-21T00:36:59.083914Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"question = \"What is Data Engineering?\"\nresponse = generate_text(question, max_length=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:36:59.085558Z","iopub.execute_input":"2025-10-21T00:36:59.085831Z","iopub.status.idle":"2025-10-21T00:38:01.973325Z","shell.execute_reply.started":"2025-10-21T00:36:59.085808Z","shell.execute_reply":"2025-10-21T00:38:01.972490Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2479: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(response[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T00:38:10.548234Z","iopub.execute_input":"2025-10-21T00:38:10.548466Z","iopub.status.idle":"2025-10-21T00:38:10.552678Z","shell.execute_reply.started":"2025-10-21T00:38:10.548452Z","shell.execute_reply":"2025-10-21T00:38:10.551791Z"}},"outputs":[{"name":"stdout","text":"What is Data Engineering? What are the skills needed for a data engineer?\n\nHere is a simple way to understand Data Engineering:\n\nData Engineering is the process of designing, building, and maintaining the data infrastructure of an organization. It involves creating data pipelines, data warehouses, and data lakes to store, process, and analyze data. Data engineers work with data from various sources, including structured data from relational databases and semi-structured data from sources like JSON, XML, or NoSQL databases.\n\nHere are some of the key skills required for a data engineer:\n\n1. Programming Skills: Data engineers need to have strong programming skills, especially in languages like Python, SQL, and Java. These languages are widely used in data engineering for tasks like data manipulation, data processing, and creating data pipelines.\n\n2. Database Knowledge: Data engineers should have a solid understanding of databases, including both relational databases (like MySQL, PostgreSQL) and NoSQL databases (like MongoDB, Cassandra). They should also be familiar with data warehousing concepts and tools like Amazon Redshift, Google BigQuery, and Snowflake.\n\n3. Data Processing and ETL: Data engineers need to be proficient in data processing frameworks and tools like Apache Spark, Apache Hadoop, and Apache Beam. They should also have experience with ETL (Extract, Transform, Load) processes, which involve extracting data from various sources, transforming it into a usable format, and loading it into a data warehouse or data lake.\n\n4. Cloud Platforms: Data engineers should have experience working with cloud platforms like Amazon Web Services (AWS), Microsoft Azure, or Google Cloud Platform (GCP). These platforms offer a wide range of services for data storage, processing, and analysis.\n\n5. Data Pipeline and Workflow Management: Data engineers should be familiar with tools for creating and managing data pipelines and workflows, such as Apache Airflow, Luigi, or Prefect.\n\n6. Data Quality and Governance: Data engineers should have a good understanding of data quality concepts and tools for ensuring the accuracy, completeness, and consistency of data. They should also be familiar with data governance principles and practices for managing access, security, and compliance.\n\n7. Soft Skills: In addition to technical skills, data engineers should also possess strong communication and collaboration skills, as they often work with data scientists, business analysts, and other stakeholders to deliver data-driven insights.\n\nOverall, data engineering is a multifaceted role that requires a broad set of skills,\n","output_type":"stream"}],"execution_count":32}]}